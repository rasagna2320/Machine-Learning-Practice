{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Santander Customer Satisfaction Dataset Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "LEf3jUfRQNrU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defbquisJjZW",
        "outputId": "7d631c92-e0aa-4fdd-e59a-4630a8e29cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
            "0   1     2     23                 0.0                      0.0   \n",
            "1   3     2     34                 0.0                      0.0   \n",
            "2   4     2     23                 0.0                      0.0   \n",
            "3   8     2     37                 0.0                    195.0   \n",
            "4  10     2     39                 0.0                      0.0   \n",
            "\n",
            "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
            "0                      0.0                      0.0                      0.0   \n",
            "1                      0.0                      0.0                      0.0   \n",
            "2                      0.0                      0.0                      0.0   \n",
            "3                    195.0                      0.0                      0.0   \n",
            "4                      0.0                      0.0                      0.0   \n",
            "\n",
            "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
            "0                      0.0                      0.0  ...   \n",
            "1                      0.0                      0.0  ...   \n",
            "2                      0.0                      0.0  ...   \n",
            "3                      0.0                      0.0  ...   \n",
            "4                      0.0                      0.0  ...   \n",
            "\n",
            "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
            "0                      0.0                      0.0                     0.0   \n",
            "1                      0.0                      0.0                     0.0   \n",
            "2                      0.0                      0.0                     0.0   \n",
            "3                      0.0                      0.0                     0.0   \n",
            "4                      0.0                      0.0                     0.0   \n",
            "\n",
            "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
            "0                     0.0                      0.0                      0.0   \n",
            "1                     0.0                      0.0                      0.0   \n",
            "2                     0.0                      0.0                      0.0   \n",
            "3                     0.0                      0.0                      0.0   \n",
            "4                     0.0                      0.0                      0.0   \n",
            "\n",
            "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
            "0                     0.0                     0.0   39205.170000       0  \n",
            "1                     0.0                     0.0   49278.030000       0  \n",
            "2                     0.0                     0.0   67333.770000       0  \n",
            "3                     0.0                     0.0   64007.970000       0  \n",
            "4                     0.0                     0.0  117310.979016       0  \n",
            "\n",
            "[5 rows x 371 columns]\n"
          ]
        }
      ],
      "source": [
        "#Data Collection\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"Santander Customer Satisfaction_train.csv\")\n",
        "print(df.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling null values\n",
        "# Can use ffill but may lead to biased prediction\n",
        "# So, let's separate categorical and numerical columns\n",
        "\n",
        "print(\"Datatypes group by:\")\n",
        "print(df.columns.to_series().groupby(df.dtypes).apply(list))\n",
        "\n",
        "# First separate target variable to avoid losing it in get_dummies\n",
        "y = df[\"TARGET\"]\n",
        "X = df.drop(\"TARGET\", axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "898-TA-6Kajl",
        "outputId": "cda0a7f9-14d5-4227-ed52-83268ec4f071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatypes group by:\n",
            "int64      [ID, var3, var15, ind_var1_0, ind_var1, ind_va...\n",
            "float64    [imp_ent_var16_ult1, imp_op_var39_comer_ult1, ...\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numerical and categorical features\n",
        "num_fea = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "cat_fea = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n"
      ],
      "metadata": {
        "id": "FfTa_1dmPCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values\n",
        "X[num_fea] = X[num_fea].fillna(X[num_fea].median())\n",
        "X[cat_fea] = X[cat_fea].fillna(\"Unknown\")"
      ],
      "metadata": {
        "id": "IG_QqFLaPF1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical to dummies\n",
        "X = pd.get_dummies(X, columns=cat_fea, drop_first=True)\n",
        "\n",
        "# If there is an ID column or similar, drop it\n",
        "if \"ID\" in X.columns:\n",
        "    X.drop(columns=[\"ID\"], inplace=True)"
      ],
      "metadata": {
        "id": "ky7qR-eTPKHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "# stratify=y maintains the same class distribution in train and test sets.\n",
        "# random_state=42 is just a popular arbitrary choice among programmers"
      ],
      "metadata": {
        "id": "hBwWNHGbPOvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "udP7GN_DQYKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Methods for Feature Selection\n",
        "\n",
        "### Basic Filter Methods\n",
        "1. Constant Features Removal  \n",
        "2. Quasi-Constant Features Removal  \n",
        "3. Duplicate Features Removal  \n",
        "\n",
        "### Statistical Filter Methods\n",
        "1. Pearson Correlation  \n",
        "2. Spearman Rank Correlation  \n",
        "3. ANOVA F-test  \n",
        "4. Mutual Information (regression)  \n",
        "5. Chi-square Test  \n",
        "6. Mutual Information (classification)  \n",
        "7. Cramér’s V"
      ],
      "metadata": {
        "id": "GqnZnzsJPyrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic filter methods\n",
        "#1.Removing Constant features\n",
        "const = []\n",
        "for features in X_train:\n",
        "  if(X_train[features].std()==0):\n",
        "    const.append(features)\n",
        "print(\"Number of constant features:\",len(const))\n",
        "X_train.drop(labels=const,axis=1,inplace=True)\n",
        "X_test.drop(labels=const,axis=1,inplace=True)\n",
        "\n",
        "#2.Removing quasi constant features\n",
        "quasi_constant = []\n",
        "for feature in X_train.columns:\n",
        "  predominant = (X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.999):\n",
        "    quasi_constant.append(feature)\n",
        "print(\"Number of quasi constant features:\",len(quasi_constant))\n",
        "X_train.drop(labels=quasi_constant,axis=1,inplace=True)\n",
        "X_test.drop(labels=quasi_constant,axis=1,inplace=True)#Apply same removal to X_test\n",
        "\n",
        "#3.Duplicated features\n",
        "duplicates = []\n",
        "for i in range(len(X_train.columns)):\n",
        "  col1 = X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])): #Not ==, as it won't return a single True of False\n",
        "      duplicates.append(col2)\n",
        "print(\"Number of duplicate features:\",len(duplicates))\n",
        "X_train.drop(labels=duplicates,axis=1,inplace=True)\n",
        "X_test.drop(labels=duplicates,axis=1,inplace=True)#Apply same removal to X_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vENYYDEUPRez",
        "outputId": "425c484b-0459-4486-d60c-dc59fa4ca2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of constant features: 57\n",
            "Number of quasi constant features: 89\n",
            "Number of duplicate features: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistical Filter Methods\n",
        "#Even though we’ve already one-hot encoded everything, statistical filter methods still differ based on original feature type\n",
        "#Target is Survived-Categorical, and this is a classification problem\n",
        "#Numerical features\n",
        "num_features=[col for col in X_train.columns if not set(X_train[col].unique()).issubset({0,1})]\n",
        "cat_features = [col for col in X_train.columns if set(X_train[col].unique()).issubset({0,1})]\n",
        "#Input numerical and output categorical --> Anova or Kendalls\n",
        "from sklearn.feature_selection import f_classif,SelectKBest\n",
        "#1. Anova\n",
        "f_values,p_values = f_classif(X_train[num_features],y_train)\n",
        "anova_df=pd.DataFrame({\n",
        "    \"Numerical Features\":num_features,\n",
        "    \"F_values\":f_values,\n",
        "    \"P_values\":p_values\n",
        "    })\n",
        "anova_df.sort_values(by=\"P_values\",inplace=True)\n",
        "significant_numeric_features = anova_df[anova_df[\"P_values\"]<0.05][\"Numerical Features\"].tolist()\n",
        "print(\"Selected Numerical Features:\", significant_numeric_features)\n",
        "#Input categorical and output categroical --> Chi2 or Mutual Info\n",
        "#2.chi2\n",
        "from sklearn.feature_selection import chi2\n",
        "chi2_values,p_values=chi2(X_train[cat_features],y_train)\n",
        "chi2_df=pd.DataFrame({\n",
        "    \"Categorical Features\":cat_features,\n",
        "    \"Chi2_values\":chi2_values,\n",
        "    \"p_values\":p_values\n",
        "     })\n",
        "chi2_df.sort_values(by=\"p_values\",inplace=True)\n",
        "significant_chi2_features=chi2_df[chi2_df[\"p_values\"]<0.05][\"Categorical Features\"].tolist()\n",
        "print(\"Selected Features from Chi2 test:\", significant_chi2_features)\n",
        "#3. Mutual info\n",
        "from sklearn.feature_selection import mutual_info_classif,SelectKBest\n",
        "#We explored manual filtering(MI>0) so far, another way is by selecting K best features\n",
        "selector = SelectKBest(score_func=mutual_info_classif,k=10)\n",
        "#Fit on our dataset\n",
        "selector.fit(X_train[cat_features],y_train)\n",
        "#We can use transform on selector to directly transform the dataset or can extract the features like we did before\n",
        "significant_mi_features=X_train[cat_features].columns[selector.get_support()].tolist()\n",
        "print(\"Selected Features from MI test:\",significant_mi_features)\n",
        "\n",
        "#Numerical features, Categorical Features(from both chi2 and mi) --> union all to filter from dataset\n",
        "final_selected_features=list(set(significant_numeric_features+significant_chi2_features+significant_mi_features)) #Set conversion is for removing duplicates, converting to list is to use it as indexer\n",
        "#Filter\n",
        "X_train=X_train[final_selected_features]\n",
        "# Ensure that X_test has the same columns as X_train after feature selection and encoding.\n",
        "# Some dummy variables or features may be missing in X_test if certain categories\n",
        "# are not present in the test set. To avoid errors during model prediction,\n",
        "# we add these missing columns filled with zeros to X_test,\n",
        "# then reorder columns to exactly match X_train.\n",
        "for col in X_train.columns:\n",
        "    if col not in X_test.columns:\n",
        "        X_test[col] = 0\n",
        "X_test = X_test[X_train.columns]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQNBGSglP2an",
        "outputId": "6ea8341b-99da-4898-ce95-2f2ed627ebc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Numerical Features: ['num_meses_var5_ult3', 'num_var30', 'num_var5', 'num_var42', 'var15', 'var36', 'num_var4', 'num_var35', 'num_var8_0', 'num_var13', 'num_var13_0', 'saldo_var30', 'num_meses_var13_corto_ult3', 'num_var13_corto', 'num_var13_corto_0', 'num_var12', 'imp_op_var39_efect_ult1', 'num_var5_0', 'imp_op_var41_efect_ult1', 'num_var8', 'num_var24', 'num_var30_0', 'num_meses_var12_ult3', 'num_var22_ult1', 'saldo_var13', 'num_var24_0', 'num_meses_var8_ult3', 'imp_op_var39_efect_ult3', 'num_var41_0', 'imp_op_var41_ult1', 'imp_op_var39_ult1', 'imp_op_var41_efect_ult3', 'num_aport_var13_hace3', 'num_var39_0', 'saldo_var13_corto', 'saldo_medio_var13_corto_ult1', 'num_op_var39_efect_ult1', 'saldo_medio_var13_corto_ult3', 'num_op_var41_efect_ult1', 'saldo_var42', 'num_var26_0', 'num_var25_0', 'saldo_medio_var13_corto_hace2', 'imp_aport_var13_hace3', 'num_op_var39_efect_ult3', 'saldo_var12', 'saldo_var24', 'num_var12_0', 'num_op_var41_efect_ult3', 'saldo_medio_var12_ult3', 'saldo_medio_var12_ult1', 'num_med_var22_ult3', 'saldo_medio_var5_hace2', 'num_var13_largo_0', 'num_var13_largo', 'saldo_medio_var5_ult3', 'num_meses_var13_largo_ult3', 'num_var43_recib_ult1', 'var38', 'saldo_medio_var12_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult1', 'num_var22_ult3', 'num_sal_var16_ult1', 'saldo_var13_largo', 'saldo_medio_var13_corto_hace3', 'num_var45_ult1', 'saldo_var5', 'num_var42_0', 'saldo_medio_var13_largo_ult3', 'saldo_medio_var13_largo_hace2', 'num_op_var39_ult1', 'saldo_medio_var13_largo_ult1', 'num_op_var41_ult1', 'saldo_var40', 'num_var40', 'num_var1', 'num_var20_0', 'num_var22_hace2', 'saldo_medio_var12_hace3', 'imp_trans_var37_ult1', 'num_op_var41_ult3', 'num_op_var39_ult3', 'num_var20', 'num_ent_var16_ult1', 'imp_aport_var13_ult1', 'num_trasp_var11_ult1']\n",
            "Selected Features from Chi2 test: ['ind_var5', 'ind_var30', 'ind_var8_0', 'ind_var13', 'ind_var13_0', 'ind_var12_0', 'ind_var13_corto', 'ind_var13_corto_0', 'ind_var12', 'ind_var8', 'ind_var24', 'ind_var24_0', 'ind_var26_cte', 'ind_var25_cte', 'ind_var26_0', 'ind_var25_0', 'ind_var14_0', 'ind_var43_recib_ult1', 'ind_var13_largo_0', 'ind_var13_largo', 'ind_var40', 'ind_var1', 'ind_var20_0', 'ind_var19', 'ind_var39_0', 'ind_var10_ult1', 'ind_var41_0', 'ind_var20', 'ind_var10cte_ult1', 'ind_var9_ult1', 'ind_var31_0']\n",
            "Selected Features from MI test: ['ind_var5_0', 'ind_var5', 'ind_var8_0', 'ind_var13_corto_0', 'ind_var24', 'ind_var30_0', 'ind_var30', 'ind_var37_cte', 'ind_var39_0', 'ind_var41_0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset after data preprocessing and feature selection\n",
        "print(X_train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKpUa51nQE0V",
        "outputId": "41d1bead-d9b0-4dc4-de54-ba7af42732f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['saldo_medio_var13_corto_ult1', 'num_var45_ult1',\n",
            "       'saldo_medio_var5_hace2', 'num_var35', 'num_var24_0', 'saldo_var42',\n",
            "       'imp_op_var41_efect_ult3', 'ind_var8_0', 'num_op_var39_ult3',\n",
            "       'imp_aport_var13_ult1',\n",
            "       ...\n",
            "       'num_var8', 'num_var43_recib_ult1', 'num_var1', 'ind_var41_0',\n",
            "       'num_var5_0', 'ind_var24', 'var38', 'ind_var14_0', 'num_op_var39_ult1',\n",
            "       'num_op_var39_efect_ult3'],\n",
            "      dtype='object', length=121)\n"
          ]
        }
      ]
    }
  ]
}