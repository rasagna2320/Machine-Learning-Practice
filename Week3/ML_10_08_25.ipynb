{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_YfQWWak8O8a",
        "0m3ihRxxonfq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Titanic Dataset Preprocessing"
      ],
      "metadata": {
        "id": "_YfQWWak8O8a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLvDPfFe7QRK",
        "outputId": "e827afb0-8627-4cca-e617-8d557b1e8b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "#Data Collection\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"titanic_train.csv\")\n",
        "print(df.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling null values\n",
        "df.ffill(inplace=True) #Forward fill\n",
        "df.bfill(inplace=True) #Backward fill\n",
        "print(df.isnull().any())  #If any null values, returns True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KgdtJSe8rPq",
        "outputId": "e6ffe62e-7eff-4677-e367-99b9e162413c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    False\n",
            "Survived       False\n",
            "Pclass         False\n",
            "Name           False\n",
            "Sex            False\n",
            "Age            False\n",
            "SibSp          False\n",
            "Parch          False\n",
            "Ticket         False\n",
            "Fare           False\n",
            "Cabin          False\n",
            "Embarked       False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Data Exploration\n",
        "print(df.index)\n",
        "print(df.columns)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "XBfXbayI-uKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10fe45b-96c3-4f86-d987-630cb64abb8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=891, step=1)\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n",
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding each column\n",
        "\n",
        "| Column       | Data Type             | Action                                     | Reason                                         |\n",
        "|--------------|-----------------------|--------------------------------------------|------------------------------------------------|\n",
        "| PassengerId  | int64                 | Drop                                       | Unique identifier, no predictive value          |\n",
        "| Survived     | int64                 | Keep as target                             | Target variable (label)                          |\n",
        "| Name         | object                | Drop (or extract titles before dropping)  | Raw name is not predictive, but titles may help|\n",
        "| Sex          | object (categorical)  | Convert to binary numeric (0 for male, 1 for female) | Important categorical feature, avoid ordinal implication |\n",
        "| Age          | float64               | Keep as is                                | Important numerical feature                      |\n",
        "| SibSp        | int64                 | Keep as is, consider creating family size | Counts siblings/spouses aboard                    |\n",
        "| Parch        | int64                 | Keep as is, consider creating family size | Counts parents/children aboard                    |\n",
        "| Ticket       | object                | Extract prefix as categorical feature, then drop original | Raw ticket noisy; prefix may hold useful info    |\n",
        "| Fare         | float64               | Keep as is, scale if necessary            | Reflects passenger class and socio-economic status |\n",
        "| Cabin        | object                | Extract deck letter, impute missing values, encode | Deck location impacts survival                     |\n",
        "| Embarked     | object                | Impute missing values, encode             | Port of embarkation affects survival             |\n",
        "       |\n",
        "\n"
      ],
      "metadata": {
        "id": "uJp7H03xYdRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling different columns\n",
        "#Drop ones that don't contribute\n",
        "df.drop('PassengerId',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "WluW_u4NVBmO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode nominal categorical values\n",
        "df[\"Sex\"]=df[\"Sex\"].map({\"male\":0,\"female\":1})"
      ],
      "metadata": {
        "id": "O1OraC8YopLG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract useful prefixes\n",
        "import re\n",
        "df[\"Title\"]=df[\"Name\"].str.extract(r\",\\s*([^\\.]+)\\.\")\n",
        "df.drop(\"Name\",axis=1,inplace=True)\n",
        "\n",
        "df[\"Deck\"] = df[\"Ticket\"].str.extract(r\"([A-Za-z\\.]+)\")\n",
        "df[\"Deck\"] = df[\"Deck\"].fillna(\"NoPrefix\")\n",
        "df.drop(\"Ticket\", axis=1, inplace=True)\n",
        "#But too many prefixes for deck\n",
        "threshold=10\n",
        "prefix_counts = df[\"Deck\"].value_counts()\n",
        "rare_prefixes = prefix_counts[prefix_counts < threshold].index\n",
        "df[\"Deck\"] = df[\"Deck\"].replace(rare_prefixes, 'Other')\n",
        "# One-Hot Encode 'Deck' column, drop_first=True avoids dummy variable trap\n",
        "df = pd.get_dummies(df, columns=[\"Deck\"], drop_first=True)"
      ],
      "metadata": {
        "id": "eRnGWSRXosMn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After data preprocessing\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE8haYKUweo0",
        "outputId": "2d1e00d1-c55d-4fe7-c21b-0170aeb11bf1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Cabin Embarked Title  \\\n",
            "0         0       3    0  22.0      1      0   7.2500   C85        S    Mr   \n",
            "1         1       1    1  38.0      1      0  71.2833   C85        C   Mrs   \n",
            "2         1       3    1  26.0      0      0   7.9250   C85        S  Miss   \n",
            "3         1       1    1  35.0      1      0  53.1000  C123        S   Mrs   \n",
            "4         0       3    0  35.0      0      0   8.0500  C123        S    Mr   \n",
            "\n",
            "   Deck_C.A.  Deck_NoPrefix  Deck_Other  Deck_PC  Deck_SC  Deck_SOTON  \\\n",
            "0      False          False       False    False    False       False   \n",
            "1      False          False       False     True    False       False   \n",
            "2      False          False       False    False    False       False   \n",
            "3      False           True       False    False    False       False   \n",
            "4      False           True       False    False    False       False   \n",
            "\n",
            "   Deck_STON  \n",
            "0      False  \n",
            "1      False  \n",
            "2       True  \n",
            "3      False  \n",
            "4      False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and Test Data Splitting"
      ],
      "metadata": {
        "id": "0m3ihRxxonfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=df.drop(\"Survived\",axis=1)\n",
        "y=df[\"Survived\"]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)\n",
        "#stratify=y maintains the same class distribution in train and test sets.\n",
        "#random_state=42 The number 42 is just a popular arbitrary choice among programmers"
      ],
      "metadata": {
        "id": "LX1OCWg3qnkn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OJ3STtNSmzG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Methods for Feature Selection\n",
        "\n",
        "### Basic Filter Methods\n",
        "1. Constant Features Removal  \n",
        "2. Quasi-Constant Features Removal  \n",
        "3. Duplicate Features Removal  \n",
        "\n",
        "### Statistical Filter Methods\n",
        "1. Pearson Correlation  \n",
        "2. Spearman Rank Correlation  \n",
        "3. ANOVA F-test  \n",
        "4. Mutual Information (regression)  \n",
        "5. Chi-square Test  \n",
        "6. Mutual Information (classification)  \n",
        "7. Cramér’s V  \n"
      ],
      "metadata": {
        "id": "-VCUSgX7o40C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Filter methods\n",
        "cat_columns = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "X_train=pd.get_dummies(X_train,columns=cat_columns,drop_first=True)\n",
        "X_train=X_train.astype(int)\n",
        "X_test=pd.get_dummies(X_test,columns=cat_columns,drop_first=True)\n",
        "X_test=X_test.astype(int)\n",
        "print(df.dtypes)  # Verify all are numeric\n",
        "#1.Removing Constant features\n",
        "const = []\n",
        "for features in X_train:\n",
        "  if(X_train[features].std()==0):\n",
        "    const.append(features)\n",
        "print(\"Number of constant features:\",len(const))\n",
        "X_train.drop(labels=const,axis=1,inplace=True)\n",
        "X_test.drop(labels=const,axis=1,inplace=True)\n",
        "\n",
        "#2.Removing quasi constant features\n",
        "quasi_constant = []\n",
        "for feature in X_train.columns:\n",
        "  predominant = (X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.999):\n",
        "    quasi_constant.append(feature)\n",
        "print(\"Number of quasi constant features:\",len(quasi_constant))\n",
        "X_train.drop(labels=quasi_constant,axis=1,inplace=True)\n",
        "X_test.drop(labels=quasi_constant,axis=1,inplace=True)#Apply same removal to X_test\n",
        "\n",
        "#3.Duplicated features\n",
        "duplicates = []\n",
        "for i in range(len(X_train.columns)):\n",
        "  col1 = X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])): #Not ==, as it won't return a single True of False\n",
        "      duplicates.append(col2)\n",
        "print(\"Number of duplicate features:\",len(duplicates))\n",
        "X_train.drop(labels=duplicates,axis=1,inplace=True)\n",
        "X_test.drop(labels=duplicates,axis=1,inplace=True)#Apply same removal to X_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U-F44Q2myJp",
        "outputId": "ec728581-7d5b-490c-dcf2-4023b3448efd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Survived           int64\n",
            "Pclass             int64\n",
            "Sex                int64\n",
            "Age              float64\n",
            "SibSp              int64\n",
            "Parch              int64\n",
            "Fare             float64\n",
            "Cabin             object\n",
            "Embarked          object\n",
            "Title             object\n",
            "Deck_C.A.           bool\n",
            "Deck_NoPrefix       bool\n",
            "Deck_Other          bool\n",
            "Deck_PC             bool\n",
            "Deck_SC             bool\n",
            "Deck_SOTON          bool\n",
            "Deck_STON           bool\n",
            "dtype: object\n",
            "Number of constant features: 0\n",
            "Number of quasi constant features: 0\n",
            "Number of duplicate features: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistical Filter Methods\n",
        "#Even though we’ve already one-hot encoded everything, statistical filter methods still differ based on original feature type\n",
        "#Target is Survived-Categorical, and this is a classification problem\n",
        "#Numerical features\n",
        "num_features=[col for col in X_train.columns if not set(X_train[col].unique()).issubset({0,1})]\n",
        "cat_features = [col for col in X_train.columns if set(X_train[col].unique()).issubset({0,1})]\n",
        "#Input numerical and output categorical --> Anova or Kendalls\n",
        "from sklearn.feature_selection import f_classif,SelectKBest\n",
        "#1. Anova\n",
        "f_values,p_values = f_classif(X_train[num_features],y_train)\n",
        "anova_df=pd.DataFrame({\n",
        "    \"Numerical Features\":num_features,\n",
        "    \"F_values\":f_values,\n",
        "    \"P_values\":p_values\n",
        "    })\n",
        "anova_df.sort_values(by=\"P_values\",inplace=True)\n",
        "significant_numeric_features = anova_df[anova_df[\"P_values\"]<0.05][\"Numerical Features\"].tolist()\n",
        "print(\"Selected Numerical Features:\", significant_numeric_features)\n",
        "#Input categorical and output categroical --> Chi2 or Mutual Info\n",
        "#2.chi2\n",
        "from sklearn.feature_selection import chi2\n",
        "chi2_values,p_values=chi2(X_train[cat_features],y_train)\n",
        "chi2_df=pd.DataFrame({\n",
        "    \"Categorical Features\":cat_features,\n",
        "    \"Chi2_values\":chi2_values,\n",
        "    \"p_values\":p_values\n",
        "     })\n",
        "chi2_df.sort_values(by=\"p_values\",inplace=True)\n",
        "significant_chi2_features=chi2_df[chi2_df[\"p_values\"]<0.05][\"Categorical Features\"].tolist()\n",
        "print(\"Selected Features from Chi2 test:\", significant_chi2_features)\n",
        "#3. Mutual info\n",
        "from sklearn.feature_selection import mutual_info_classif,SelectKBest\n",
        "#We explored manual filtering(MI>0) so far, another way is by selecting K best features\n",
        "selector = SelectKBest(score_func=mutual_info_classif,k=10)\n",
        "#Fit on our dataset\n",
        "selector.fit(X_train[cat_features],y_train)\n",
        "#We can use transform on selector to directly transform the dataset or can extract the features like we did before\n",
        "significant_mi_features=X_train[cat_features].columns[selector.get_support()].tolist()\n",
        "print(\"Selected Features from MI test:\",significant_mi_features)\n",
        "\n",
        "#Numerical features, Categorical Features(from both chi2 and mi) --> union all to filter from dataset\n",
        "final_selected_features=list(set(significant_numeric_features+significant_chi2_features+significant_mi_features)) #Set conversion is for removing duplicates, converting to list is to use it as indexer\n",
        "#Filter\n",
        "X_train=X_train[final_selected_features]\n",
        "# Ensure that X_test has the same columns as X_train after feature selection and encoding.\n",
        "# Some dummy variables or features may be missing in X_test if certain categories\n",
        "# are not present in the test set. To avoid errors during model prediction,\n",
        "# we add these missing columns filled with zeros to X_test,\n",
        "# then reorder columns to exactly match X_train.\n",
        "for col in X_train.columns:\n",
        "    if col not in X_test.columns:\n",
        "        X_test[col] = 0\n",
        "X_test = X_test[X_train.columns]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9F8cpf-6Xsd",
        "outputId": "39a282c9-c599-4f46-deee-b75292d13de1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Numerical Features: ['Pclass', 'Fare', 'Parch', 'Age']\n",
            "Selected Features from Chi2 test: ['Sex', 'Title_Mr', 'Title_Mrs', 'Title_Miss', 'Deck_PC', 'Embarked_S', 'Cabin_A34', 'Cabin_D33', 'Cabin_C110', 'Title_Master']\n",
            "Selected Features from MI test: ['Sex', 'Deck_SOTON', 'Cabin_B78', 'Cabin_C106', 'Cabin_C30', 'Cabin_C7', 'Cabin_E40', 'Title_Miss', 'Title_Mr', 'Title_Mrs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset after data preprocessing and feature selection\n",
        "print(X_train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Zw31xGNfMf",
        "outputId": "5f5fddef-1ed0-4635-f631-0055902a0102"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Cabin_D33', 'Cabin_C106', 'Title_Miss', 'Cabin_A34', 'Parch', 'Sex',\n",
            "       'Cabin_C110', 'Deck_PC', 'Cabin_C30', 'Embarked_S', 'Fare', 'Title_Mrs',\n",
            "       'Title_Mr', 'Pclass', 'Cabin_E40', 'Age', 'Deck_SOTON', 'Cabin_B78',\n",
            "       'Title_Master', 'Cabin_C7'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ]
}